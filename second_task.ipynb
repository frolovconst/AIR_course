{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sc\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# importing training and test data\n",
    "\n",
    "def read_txt(path):\n",
    "    doc = open(path, 'r')\n",
    "    content = doc.read()\n",
    "    doc.close()    \n",
    "    return content\n",
    "    \n",
    "sum_tr = read_txt('data/LinkedIn/sum_train.txt')\n",
    "exp_tr = read_txt('data/LinkedIn/exp_train.txt')\n",
    "edu_tr = read_txt('data/LinkedIn/edu_train.txt')\n",
    "\n",
    "sum_t = read_txt('data/LinkedIn/sum_test.txt')\n",
    "exp_t = read_txt('data/LinkedIn/exp_test.txt')\n",
    "edu_t = read_txt('data/LinkedIn/edu_test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cleaning\n",
    "\n",
    "date_pattern = re.compile(r\"(January|February|March|April|May|June|July|August|September|October|November|December)\\s+\\d\\d*\")\n",
    "year_pattern = re.compile(r'(19|20)\\d\\d')\n",
    "\n",
    "def replace_n(doc):\n",
    "    return doc.replace('\\nN A\\n', ' %NA% ')\n",
    "\n",
    "def replace_date(doc):\n",
    "    d = date_pattern.sub('%DATE%', doc)\n",
    "    d = year_pattern.sub('%YEAR%', d)\n",
    "    return d\n",
    "\n",
    "def apply_filters(doc):\n",
    "    s = replace_n(doc)\n",
    "    s = replace_date(s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sum_tr = apply_filters(sum_tr).replace('\\n', ' ')\n",
    "exp_tr = apply_filters(exp_tr).replace('\\n', ' ')\n",
    "edu_tr = apply_filters(edu_tr).replace('\\n', ' ')\n",
    "\n",
    "sum_t = apply_filters(sum_t)\n",
    "exp_t = apply_filters(exp_t)\n",
    "edu_t = apply_filters(edu_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# creating dictionary (probabilities)\n",
    "\n",
    "topics = ['smr', 'exp', 'edu']\n",
    "freqs = pd.DataFrame(columns=topics)\n",
    "total_freq = {}\n",
    "sum_num = exp_num = edu_num = 0\n",
    "\n",
    "def count_freqs(words, column):\n",
    "    for word in words:\n",
    "        if word in freqs.index:\n",
    "            freqs.loc[word][column] += 1\n",
    "        else:\n",
    "            freqs.loc[word] = [1.0, 0.0, 0.0]\n",
    "        if  word in total_freq:\n",
    "            total_freq[word] += 1\n",
    "        else:\n",
    "            total_freq[word] = 1.0\n",
    "            \n",
    "splitted = sum_tr.split()\n",
    "sum_num = len(splitted)\n",
    "count_freqs(splitted, 'smr')\n",
    "\n",
    "splitted = exp_tr.split()\n",
    "exp_num = len(splitted)\n",
    "count_freqs(splitted, 'exp')\n",
    "\n",
    "splitted = edu_tr.split()\n",
    "edu_num = len(splitted)\n",
    "count_freqs(splitted, 'edu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "freqs['smr'] = freqs['smr'] / sum_num\n",
    "freqs['edu'] = freqs['edu'] / edu_num\n",
    "freqs['exp'] = freqs['exp'] / exp_num\n",
    "\n",
    "total_sum = sum_num + exp_num + edu_num\n",
    "for word in total_freq:\n",
    "    total_freq[word] /= total_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# preparing tested data\n",
    "\n",
    "_min_len = 30 # concate small rows with next\n",
    "_buff = ' '\n",
    "\n",
    "to_test = pd.DataFrame(columns=['data', 'label','prediction'])\n",
    "i = 0\n",
    "\n",
    "rows = sum_t.split('\\n')\n",
    "for row in rows:\n",
    "    row = _buff + row\n",
    "    if len(row) > _min_len:\n",
    "        to_test.loc[i] = [row, 0, 0]\n",
    "        i += 1\n",
    "        _buff = ' '\n",
    "    else:\n",
    "        _buff = _buff + row\n",
    "\n",
    "rows = exp_t.split('\\n')\n",
    "for row in rows:\n",
    "    row = _buff + row\n",
    "    if len(row) > _min_len:\n",
    "        to_test.loc[i] = [row, 1, 1]\n",
    "        i += 1\n",
    "        _buff = ' '\n",
    "    else:\n",
    "        _buff = _buff + row\n",
    "\n",
    "rows = edu_t.split('\\n')\n",
    "for row in rows:\n",
    "    row = _buff + row\n",
    "    if len(row) > _min_len:\n",
    "        to_test.loc[i] = [row, 2, 2]\n",
    "        i += 1\n",
    "        _buff = ' '\n",
    "    else:\n",
    "        _buff = _buff + row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "c:\\anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "c:\\anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "# classification\n",
    "\n",
    "for index, row in to_test.iterrows():\n",
    "    words = row['data'].split()\n",
    "    smr = exp = edu = 0.0\n",
    "    for word in words:\n",
    "        if word in freqs.index:\n",
    "            smr += freqs.loc[word]['smr'] / total_freq[word]\n",
    "            exp += freqs.loc[word]['exp'] / total_freq[word]\n",
    "            edu += freqs.loc[word]['edu'] / total_freq[word]\n",
    "    mx = max(smr, exp, edu)\n",
    "    if smr >= mx:\n",
    "        to_test.loc[i-1]['prediction'] = 0\n",
    "    if exp >= mx:\n",
    "        to_test.loc[i-1]['prediction'] = 1\n",
    "    if edu >= mx:\n",
    "        to_test.loc[i-1]['prediction'] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        smr       1.00      1.00      1.00        78\n",
      "        exp       1.00      1.00      1.00       365\n",
      "        edu       1.00      1.00      1.00       113\n",
      "\n",
      "avg / total       1.00      1.00      1.00       556\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# estimation\n",
    "\n",
    "print (classification_report(to_test.label.tolist(), to_test.prediction.tolist(), target_names=topics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
